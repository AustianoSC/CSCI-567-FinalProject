{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from LazyProphet import LazyProphet as lp\n",
    "\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "path = 'inputs/'\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.expand_frame_repr', False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def insert_holidays(testy):\n",
    "    data = testy.copy()\n",
    "    data['nat_holiday'] = 0\n",
    "    data['reg_holiday'] = 0\n",
    "    data['loc_holiday'] = 0\n",
    "\n",
    "    stores = stores_new.copy()\n",
    "    holidays = pd.read_csv(path + 'holidays_events.csv',\n",
    "                        usecols=['date', 'type', 'locale', 'locale_name', 'transferred'],\n",
    "                        dtype={'type': 'category', 'locale': 'category', 'locale_name': 'category', 'transferred': 'bool'},\n",
    "                        parse_dates=['date'], infer_datetime_format=True\n",
    "                        )\n",
    "    holidays = holidays.reset_index()\n",
    "    stores = stores.reset_index()\n",
    "\n",
    "    for index, row in holidays.iterrows():\n",
    "        store_nbr_list = []\n",
    "        if row['locale'] == 'Local':\n",
    "            for sindex, srow in stores.iterrows():\n",
    "                if srow['city'] == row['locale_name']:\n",
    "                    data.loc[(data['date'] == row['date']) & (data['store_nbr'] == srow['store_nbr']), 'loc_holiday'] = 1\n",
    "        if row['locale'] == 'Regional':\n",
    "            for sindex, srow in stores.iterrows():\n",
    "                if srow['state'] == row['locale_name']:\n",
    "                    data.loc[(data['date'] == row['date']) & (data['store_nbr'] == srow['store_nbr']), 'reg_holiday'] = 1\n",
    "        if row['locale'] == 'National':\n",
    "            data.loc[data['date'] == row['date'], 'nat_holiday'] = 1\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Adapted from https://www.kaggle.com/code/enesdilsiz/time-series-forecasting-with-lightgbm\n",
    "def random_noise(dataframe):\n",
    "    x = np.random.normal(scale=1.5, size=(len(dataframe),))\n",
    "    return x\n",
    "\n",
    "# Data preprocessing functions\n",
    "def lag_features(dataframe, lags, feature):\n",
    "    for lag in lags:\n",
    "        dataframe[str(feature) + '_lag_' + str(lag)] = dataframe.groupby([\"store_nbr\", \"family\"])[feature].transform(\n",
    "            lambda x: x.shift(lag))\n",
    "        #+ random_noise(dataframe)\n",
    "    return dataframe\n",
    "\n",
    "def roll_mean_features(dataframe, windows, feature):\n",
    "    for window in windows:\n",
    "        dataframe[str(feature) + '_roll_mean_' + str(window)] = dataframe.groupby([\"store_nbr\", \"family\"])[feature]. \\\n",
    "                                                          transform(\n",
    "            lambda x: x.shift(1).rolling(window=window, min_periods=10, win_type=\"triang\").mean()) + random_noise(\n",
    "            dataframe)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def ewm_features(dataframe, alphas, lags, feature):\n",
    "    for alpha in alphas:\n",
    "        for lag in lags:\n",
    "            dataframe[str(feature) + '_ewm_alpha_' + str(alpha).replace(\".\", \"\") + \"_lag_\" + str(lag)] = \\\n",
    "                dataframe.groupby([\"store_nbr\", \"family\"])[feature].transform(lambda x: x.shift(lag).ewm(alpha=alpha).mean())\n",
    "    return dataframe\n",
    "\n",
    "def lag_all_features(data, features):\n",
    "    lags = [x for x in range(1,16)]\n",
    "    alphas = [0.95, 0.9, 0.8, 0.7, 0.5]\n",
    "    windows = [128, 365, 546]\n",
    "    for feature in features:\n",
    "        data = lag_features(data, lags, feature)\n",
    "        data = roll_mean_features(data, windows, feature)\n",
    "        data = ewm_features(data, alphas, lags, feature)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# Load Oil Data\n",
    "data_oil = pd.read_csv(path + 'oil.csv', parse_dates=['date'], infer_datetime_format=True)\n",
    "data_oil['dcoilwtico'].fillna(method='ffill', inplace=True)\n",
    "data_oil['ma_oil'] = data_oil['dcoilwtico'].rolling(7).mean()\n",
    "data_oil['ma_oil'].fillna(method='ffill', inplace=True)\n",
    "calendar = pd.DataFrame()\n",
    "calendar['date'] = pd.date_range('2013-01-01', '2017-08-31')\n",
    "cally = pd.merge(calendar, data_oil, how='outer', on='date' )\n",
    "cally.fillna(method='ffill', inplace=True)\n",
    "calendar = cally.copy()    #1704 rows\n",
    "\n",
    "# Load Stores\n",
    "stores_new = pd.read_csv(path + 'stores.csv',\n",
    "                         usecols=['store_nbr', 'city', 'state', 'type', 'cluster'],\n",
    "                         dtype={'store_nbr': 'category', 'city': 'category', 'state': 'category', 'type': 'category', 'cluster': 'category'})\n",
    "\n",
    "transactions = pd.read_csv(path + 'transactions.csv',\n",
    "                          usecols=['store_nbr', 'date', 'transactions'],\n",
    "                          dtype={'store_nbr': 'category', 'transactions': 'float32'},\n",
    "                          parse_dates=['date'], infer_datetime_format=True)\n",
    "\n",
    "df_train = pd.read_csv(path + 'train.csv',\n",
    "                       usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n",
    "                       dtype={'store_nbr': 'category', 'family': 'category', 'sales': 'float32', 'onpromotion': 'float32'},\n",
    "                       parse_dates=['date'], infer_datetime_format=True)\n",
    "\n",
    "train_oil = pd.merge(df_train, calendar, how='outer', on='date')\n",
    "train_oil.sort_values(by=['family','store_nbr'], axis=0, inplace=True)\n",
    "train_oil['ma_oil'].fillna(method='ffill', inplace=True)\n",
    "train_oil['dcoilwtico'].fillna(method='ffill', inplace=True)\n",
    "train_oil_trans = pd.merge(transactions, train_oil, how='outer', on =['store_nbr', 'date'])\n",
    "# train_oil_trans = train_oil_trans[train_oil_trans['family'].notna()]\n",
    "# tmp.sort_values(by=['store_nbr', 'sales'], axis=0, inplace=True)\n",
    "# train_oil_trans[train_oil_trans['transactions'].isnull()]\n",
    "train_oil_trans_stores = train_oil_trans.merge(stores_new, on='store_nbr')\n",
    "train_oil_trans_stores_holiday = insert_holidays(train_oil_trans_stores)\n",
    "# tmp = train_oil_trans_stores_holiday[train_oil_trans_stores_holiday.transactions.isnull()]\n",
    "# tmp = tmp.loc[(tmp.nat_holiday != 1) & (tmp.reg_holiday != 1) & (tmp.loc_holiday != 1)]\n",
    "# tmp\n",
    "train_oil_trans_stores_holiday.transactions.fillna(0, inplace=True)\n",
    "data = train_oil_trans_stores_holiday.copy()\n",
    "del train_oil_trans_stores_holiday, train_oil_trans_stores, train_oil_trans, train_oil, data_oil, df_train, transactions, cally\n",
    "data.sort_values(by=['store_nbr', 'family', 'date'], axis=0, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "feats = ['sales', 'ma_oil', 'dcoilwtico']\n",
    "data = lag_all_features(data, feats)\n",
    "\n",
    "# data = roll_mean_features(data, [128, 365, 546])\n",
    "# data = ewm_features(data, alphas, lags)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = data\n",
    "del data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df['year'] = df.date.dt.year\n",
    "df['month'] = df.date.dt.month\n",
    "df['quarter_of_year'] = df.date.dt.quarter\n",
    "df['week_of_year'] = df.date.dt.isocalendar().week\n",
    "df['day_of_year'] = df.date.dt.dayofyear\n",
    "df['day_of_month'] = df.date.dt.day\n",
    "# df['day_of_week'] = df.date.dt.dayofweek\n",
    "df[\"is_wknd\"] = df.date.dt.weekday // 4\n",
    "df['is_month_start'] = df.date.dt.is_month_start.astype(int)\n",
    "df['is_month_end'] = df.date.dt.is_month_end.astype(int)\n",
    "df = pd.get_dummies(df, columns=[ 'store_nbr', 'family', 'city', 'state', 'type', 'type', 'cluster'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000888 entries, 110880 to 555455\n",
      "Columns: 449 entries, date to cluster_9\n",
      "dtypes: UInt32(1), datetime64[ns](1), float32(18), float64(266), int32(2), int64(9), uint8(152)\n",
      "memory usage: 6.9 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'm4-weekly-train.csv')\n",
    "test_df = pd.read_csv(r'm4-weekly-test.csv')\n",
    "train_df.index = train_df['V1']\n",
    "train_df = train_df.drop('V1', axis = 1)\n",
    "test_df.index = test_df['V1']\n",
    "test_df = test_df.drop('V1', axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 359 entries, W1 to W359\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   V2      359 non-null    float64\n",
      " 1   V3      359 non-null    float64\n",
      " 2   V4      359 non-null    float64\n",
      " 3   V5      359 non-null    float64\n",
      " 4   V6      359 non-null    float64\n",
      " 5   V7      359 non-null    float64\n",
      " 6   V8      359 non-null    float64\n",
      " 7   V9      359 non-null    float64\n",
      " 8   V10     359 non-null    float64\n",
      " 9   V11     359 non-null    float64\n",
      " 10  V12     359 non-null    float64\n",
      " 11  V13     359 non-null    float64\n",
      " 12  V14     359 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 39.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "train = df.loc[(df.date < \"2013-07-15\"), :]\n",
    "test_df = df.loc[(df.date >= \"2013-07-15\" ) & (df.date < \"2017-07-31\")]\n",
    "\n",
    "cols = [col for col in train.columns if col not in ['date', 'sales', 'transactions' ]]\n",
    "\n",
    "train_df = train[cols]\n",
    "\n",
    "# train_df.index = train_df.sales\n",
    "# train_df = train_df.drop('sales', axis = 1)\n",
    "test_df.index = test_df.sales\n",
    "test_df = test_df.drop('sales', axis = 1)\n",
    "test_df = test_df.drop('date', axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "date            2013-07-15 00:00:00\ntransactions                 1781.0\nonpromotion                     0.0\ndcoilwtico                    106.2\nma_oil                   104.687143\n                       ...         \ncluster_5                         0\ncluster_6                         0\ncluster_7                         0\ncluster_8                         0\ncluster_9                         0\nName: 2.0, Length: 448, dtype: object"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nan, nan:   0%|          | 0/347490 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 16\u001B[0m\n\u001B[0;32m      7\u001B[0m j\u001B[38;5;241m.\u001B[39mset_description(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnp\u001B[38;5;241m.\u001B[39mmean(smapes)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnp\u001B[38;5;241m.\u001B[39mmean(naive_smape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      8\u001B[0m lp_model \u001B[38;5;241m=\u001B[39m lp\u001B[38;5;241m.\u001B[39mLazyProphet(scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m      9\u001B[0m                        seasonal_period\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m52\u001B[39m,\n\u001B[0;32m     10\u001B[0m                        n_basis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     14\u001B[0m                        linear_trend\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     15\u001B[0m                        decay_average\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 16\u001B[0m fitted \u001B[38;5;241m=\u001B[39m \u001B[43mlp_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m predictions \u001B[38;5;241m=\u001B[39m lp_model\u001B[38;5;241m.\u001B[39mpredict(\u001B[38;5;28mlen\u001B[39m(y_test))\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     18\u001B[0m smapes\u001B[38;5;241m.\u001B[39mappend(smape(y_test\u001B[38;5;241m.\u001B[39mvalues,      pd\u001B[38;5;241m.\u001B[39mSeries(predictions)\u001B[38;5;241m.\u001B[39mclip(lower\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\LazyProphet\\LazyProphet.py:209\u001B[0m, in \u001B[0;36mLazyProphet.fit\u001B[1;34m(self, y, X)\u001B[0m\n\u001B[0;32m    207\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseries_features\n\u001B[0;32m    208\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_trend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_trend:\n\u001B[1;32m--> 209\u001B[0m     fitted_trend \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_trend:\n\u001B[0;32m    211\u001B[0m     y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msubtract(y, fitted_trend)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\LazyProphet\\LazyProphet.py:109\u001B[0m, in \u001B[0;36mLazyProphet.linear_test\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m    107\u001B[0m xi \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(y) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    108\u001B[0m xi \u001B[38;5;241m=\u001B[39m xi\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[1;32m--> 109\u001B[0m slope, intercept, r_value, p_value, std_err \u001B[38;5;241m=\u001B[39m \u001B[43mstats\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinregress\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxi\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    110\u001B[0m trend_line \u001B[38;5;241m=\u001B[39m slope\u001B[38;5;241m*\u001B[39mxi\u001B[38;5;241m*\u001B[39mr_value \u001B[38;5;241m+\u001B[39m intercept\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_trend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_trend \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_stats_mstats_common.py:166\u001B[0m, in \u001B[0;36mlinregress\u001B[1;34m(x, y, alternative)\u001B[0m\n\u001B[0;32m    161\u001B[0m ymean \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(y, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    163\u001B[0m \u001B[38;5;66;03m# Average sums of square differences from the mean\u001B[39;00m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;66;03m#   ssxm = mean( (x-mean(x))^2 )\u001B[39;00m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;66;03m#   ssxym = mean( (x-mean(x)) * (y-mean(y)) )\u001B[39;00m\n\u001B[1;32m--> 166\u001B[0m ssxm, ssxym, _, ssym \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcov\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mflat\n\u001B[0;32m    168\u001B[0m \u001B[38;5;66;03m# R-value\u001B[39;00m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;66;03m#   r = ssxym / sqrt( ssxm * ssym )\u001B[39;00m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ssxm \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0.0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m ssym \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[0;32m    171\u001B[0m     \u001B[38;5;66;03m# If the denominator was going to be 0\u001B[39;00m\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mcov\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2680\u001B[0m, in \u001B[0;36mcov\u001B[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001B[0m\n\u001B[0;32m   2677\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2678\u001B[0m         w \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m aweights\n\u001B[1;32m-> 2680\u001B[0m avg, w_sum \u001B[38;5;241m=\u001B[39m \u001B[43maverage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturned\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   2681\u001B[0m w_sum \u001B[38;5;241m=\u001B[39m w_sum[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   2683\u001B[0m \u001B[38;5;66;03m# Determine the normalization\u001B[39;00m\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36maverage\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:554\u001B[0m, in \u001B[0;36maverage\u001B[1;34m(a, axis, weights, returned, keepdims)\u001B[0m\n\u001B[0;32m    550\u001B[0m     avg \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmultiply(a, wgt,\n\u001B[0;32m    551\u001B[0m                       dtype\u001B[38;5;241m=\u001B[39mresult_dtype)\u001B[38;5;241m.\u001B[39msum(axis, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkeepdims_kw) \u001B[38;5;241m/\u001B[39m scl\n\u001B[0;32m    553\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m returned:\n\u001B[1;32m--> 554\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mscl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m \u001B[38;5;241m!=\u001B[39m avg\u001B[38;5;241m.\u001B[39mshape:\n\u001B[0;32m    555\u001B[0m         scl \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mbroadcast_to(scl, avg\u001B[38;5;241m.\u001B[39mshape)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m    556\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m avg, scl\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'float' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "smapes = []\n",
    "naive_smape = []\n",
    "j = tqdm(range(len(train_df)))\n",
    "for row in j:\n",
    "    y = train_df.iloc[row, :].dropna()\n",
    "    y_test = test_df.iloc[row, :].dropna()\n",
    "    j.set_description(f'{np.mean(smapes)}, {np.mean(naive_smape)}')\n",
    "    lp_model = lp.LazyProphet(scale=True,\n",
    "                           seasonal_period=52,\n",
    "                           n_basis=10,\n",
    "                           fourier_order=10,\n",
    "                           ar=list(range(1, 53)),\n",
    "                           decay=.99,\n",
    "                           linear_trend=None,\n",
    "                           decay_average=False)\n",
    "    fitted = lp_model.fit(y)\n",
    "    predictions = lp_model.predict(len(y_test)).reshape(-1)\n",
    "    smapes.append(smape(y_test.values,      pd.Series(predictions).clip(lower=0)))\n",
    "    naive_smape.append(smape(y_test.values, np.tile(y.iloc[-1], len(y_test))))\n",
    "print(np.mean(smapes))\n",
    "print(np.mean(naive_smape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11.630263556364747, 42.86116392273107: 100%|██████████| 414/414 [00:47<00:00,  8.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.633057576291533\n",
      "43.002986836424824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'm4-hourly-train.csv')\n",
    "test_df = pd.read_csv(r'm4-hourly-test.csv')\n",
    "train_df.index = train_df['V1']\n",
    "train_df = train_df.drop('V1', axis = 1)\n",
    "test_df.index = test_df['V1']\n",
    "test_df = test_df.drop('V1', axis = 1)\n",
    "smapes = []\n",
    "naive_smape = []\n",
    "j = tqdm(range(len(train_df)))\n",
    "for row in j:\n",
    "    y = train_df.iloc[row, :].dropna()\n",
    "    y_test = test_df.iloc[row, :].dropna()\n",
    "    j.set_description(f'{np.mean(smapes)}, {np.mean(naive_smape)}')\n",
    "    lp_model = lp.LazyProphet(seasonal_period=[24,168],\n",
    "                            n_basis=10,\n",
    "                            fourier_order=10,\n",
    "                            ar=list(range(1, 25)),\n",
    "                            decay=.99)\n",
    "    fitted = lp_model.fit(y)\n",
    "    predictions = lp_model.predict(len(y_test)).reshape(-1)\n",
    "    smapes.append(smape(y_test.values, pd.Series(predictions).clip(lower=0)))\n",
    "    naive_smape.append(smape(y_test.values, np.tile(y.iloc[-1], len(y_test))))\n",
    "print(np.mean(smapes))\n",
    "print(np.mean(naive_smape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}