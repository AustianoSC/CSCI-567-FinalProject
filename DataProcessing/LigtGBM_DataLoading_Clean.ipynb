{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "THE CODE BELOW INTEGRATES THE HW4 STUFF AND ADDS THE WORK FROM ABOVE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "path = 'inputs/'\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Add holidays\n",
    "def insert_holidays(testy, stores_new):\n",
    "    data = testy.copy()\n",
    "    data['nat_holiday'] = 0\n",
    "    data['reg_holiday'] = 0\n",
    "    data['loc_holiday'] = 0\n",
    "\n",
    "    stores = stores_new.copy()\n",
    "    holidays = pd.read_csv(path + 'holidays_events.csv',\n",
    "                        usecols=['date', 'type', 'locale', 'locale_name', 'transferred'],\n",
    "                        dtype={'type': 'category', 'locale': 'category', 'locale_name': 'category', 'transferred': 'bool'},\n",
    "                        parse_dates=['date'], infer_datetime_format=True\n",
    "                        )\n",
    "    holidays = holidays.reset_index()\n",
    "    stores = stores.reset_index()\n",
    "\n",
    "    for index, row in holidays.iterrows():\n",
    "        store_nbr_list = []\n",
    "        if row['locale'] == 'Local':\n",
    "            for sindex, srow in stores.iterrows():\n",
    "                if srow['city'] == row['locale_name']:\n",
    "                    data.loc[(data['date'] == row['date']) & (data['store_nbr'] == srow['store_nbr']), 'loc_holiday'] = 1\n",
    "        if row['locale'] == 'Regional':\n",
    "            for sindex, srow in stores.iterrows():\n",
    "                if srow['state'] == row['locale_name']:\n",
    "                    data.loc[(data['date'] == row['date']) & (data['store_nbr'] == srow['store_nbr']), 'reg_holiday'] = 1\n",
    "        if row['locale'] == 'National':\n",
    "            data.loc[data['date'] == row['date'], 'nat_holiday'] = 1\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "#Adapted from https://www.kaggle.com/code/enesdilsiz/time-series-forecasting-with-lightgbm\n",
    "def random_noise(dataframe):\n",
    "    x = np.random.normal(scale=1.5, size=(len(dataframe),))\n",
    "    return x\n",
    "\n",
    "# Data preprocessing functions\n",
    "def lag_features(dataframe, lags):\n",
    "    for lag in lags:\n",
    "        dataframe['sales_lag_' + str(lag)] = dataframe.groupby([\"store_nbr\", \"family\"])['sales'].transform(\n",
    "            lambda x: x.shift(lag))\n",
    "        #+ random_noise(dataframe)\n",
    "    return dataframe\n",
    "\n",
    "def roll_mean_features(dataframe, windows):\n",
    "    for window in windows:\n",
    "        dataframe['sales_roll_mean_' + str(window)] = dataframe.groupby([\"store_nbr\", \"family\"])['sales']. \\\n",
    "                                                          transform(\n",
    "            lambda x: x.shift(1).rolling(window=window, min_periods=10, win_type=\"triang\").mean()) + random_noise(\n",
    "            dataframe)\n",
    "    return dataframe\n",
    "\n",
    "def ewm_features(dataframe, alphas, lags):\n",
    "    for alpha in alphas:\n",
    "        for lag in lags:\n",
    "            dataframe['sales_ewm_alpha_' + str(alpha).replace(\".\", \"\") + \"_lag_\" + str(lag)] = \\\n",
    "                dataframe.groupby([\"store_nbr\", \"family\"])['sales'].transform(lambda x: x.shift(lag).ewm(alpha=alpha).mean())\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# Loss Functions\n",
    "def smape(preds, target):\n",
    "    n = len(preds)\n",
    "    masked_arr = ~((preds == 0) & (target == 0))\n",
    "    preds, target = preds[masked_arr], target[masked_arr]\n",
    "    num = np.abs(preds - target)\n",
    "    denom = np.abs(preds) + np.abs(target)\n",
    "    smape_val = (200 * np.sum(num / denom)) / n\n",
    "    return smape_val\n",
    "\n",
    "\n",
    "def lgbm_smape(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    smape_val = smape(preds, labels)\n",
    "    return 'SMAPE', smape_val, False\n",
    "\n",
    "\n",
    "def rmsle_lgbm(y_pred, data):\n",
    "    y_true = np.array(data.get_label())\n",
    "    score = np.sqrt(np.mean(np.power(np.log1p(y_true) - np.log1p(y_pred), 2)))\n",
    "    return 'rmsle', score, False\n",
    "\n",
    "# Plotting and post processing functions\n",
    "def plot_lgb_importances(model, plot=False, num=10):\n",
    "    gain = model.feature_importance('gain')\n",
    "    feat_imp = pd.DataFrame({'feature': model.feature_name(),\n",
    "                             'split': model.feature_importance('split'),\n",
    "                             'gain': 100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.set(font_scale=1)\n",
    "        sns.barplot(x=\"gain\", y=\"feature\", data=feat_imp[0:25])\n",
    "        plt.title('feature')\n",
    "        plt.tight_layout()\n",
    "        plt.show(block=True)\n",
    "    else:\n",
    "        print(feat_imp.head(num))\n",
    "    return feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load Oil Data\n",
    "data_oil = pd.read_csv(path + 'oil.csv', parse_dates=['date'], infer_datetime_format=True)\n",
    "data_oil['dcoilwtico'].fillna(method='ffill', inplace=True)\n",
    "data_oil['ma_oil'] = data_oil['dcoilwtico'].rolling(7).mean()\n",
    "data_oil['ma_oil'].fillna(method='ffill', inplace=True)\n",
    "calendar = pd.DataFrame()\n",
    "calendar['date'] = pd.date_range('2013-01-01', '2017-08-31')\n",
    "cally = pd.merge(calendar, data_oil, how='outer', on='date' )\n",
    "cally.fillna(method='ffill', inplace=True)\n",
    "calendar = cally.copy()    #1704 rows\n",
    "\n",
    "# Load Stores\n",
    "stores_new = pd.read_csv(path + 'stores.csv',\n",
    "                         usecols=['store_nbr', 'city', 'state', 'type', 'cluster'],\n",
    "                         dtype={'store_nbr': 'category', 'city': 'category', 'state': 'category', 'type': 'category', 'cluster': 'category'})\n",
    "\n",
    "transactions = pd.read_csv(path + 'transactions.csv',\n",
    "                          usecols=['store_nbr', 'date', 'transactions'],\n",
    "                          dtype={'store_nbr': 'category', 'transactions': 'float32'},\n",
    "                          parse_dates=['date'], infer_datetime_format=True)\n",
    "\n",
    "df_train = pd.read_csv(path + 'train.csv',\n",
    "                       usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n",
    "                       dtype={'store_nbr': 'category', 'family': 'category', 'sales': 'float32', 'onpromotion': 'float32'},\n",
    "                       parse_dates=['date'], infer_datetime_format=True)\n",
    "\n",
    "train_oil = pd.merge(df_train, calendar, how='outer', on='date')\n",
    "train_oil.sort_values(by=['family','store_nbr'], axis=0, inplace=True)\n",
    "train_oil['ma_oil'].fillna(method='ffill', inplace=True)\n",
    "train_oil['dcoilwtico'].fillna(method='ffill', inplace=True)\n",
    "train_oil_trans = pd.merge(transactions, train_oil, how='outer', on =['store_nbr', 'date'])\n",
    "# train_oil_trans = train_oil_trans[train_oil_trans['family'].notna()]\n",
    "# tmp.sort_values(by=['store_nbr', 'sales'], axis=0, inplace=True)\n",
    "# train_oil_trans[train_oil_trans['transactions'].isnull()]\n",
    "train_oil_trans_stores = train_oil_trans.merge(stores_new, on='store_nbr')\n",
    "train_oil_trans_stores_holiday = insert_holidays(train_oil_trans_stores, stores_new)\n",
    "# tmp = train_oil_trans_stores_holiday[train_oil_trans_stores_holiday.transactions.isnull()]\n",
    "# tmp = tmp.loc[(tmp.nat_holiday != 1) & (tmp.reg_holiday != 1) & (tmp.loc_holiday != 1)]\n",
    "# tmp\n",
    "train_oil_trans_stores_holiday.transactions.fillna(0, inplace=True)\n",
    "data = train_oil_trans_stores_holiday.copy()\n",
    "del train_oil_trans_stores_holiday, train_oil_trans_stores, train_oil_trans, train_oil, data_oil, df_train, transactions, cally\n",
    "data.sort_values(by=['store_nbr', 'family', 'date'], axis=0, inplace=True)\n",
    "# data.family.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lags = [x for x in range(1,16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = lag_features(data, lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = data.copy()\n",
    "df['year'] = df.date.dt.year\n",
    "df['month'] = df.date.dt.month\n",
    "df['quarter_of_year'] = df.date.dt.quarter\n",
    "df['week_of_year'] = df.date.dt.isocalendar().week\n",
    "df['day_of_year'] = df.date.dt.dayofyear\n",
    "df['day_of_month'] = df.date.dt.day\n",
    "# df['day_of_week'] = df.date.dt.dayofweek\n",
    "df[\"is_wknd\"] = df.date.dt.weekday // 4\n",
    "df['is_month_start'] = df.date.dt.is_month_start.astype(int)\n",
    "df['is_month_end'] = df.date.dt.is_month_end.astype(int)\n",
    " # pd.DataFrame({\"sales\": df[\"sales\"].values[0:10],\n",
    " #              \"lag1\": df[\"sales\"].shift(1).values[0:10],\n",
    " #              \"lag2\": df[\"sales\"].shift(2).values[0:10],\n",
    " #              \"lag3\": df[\"sales\"].shift(3).values[0:10],\n",
    " #              \"lag4\": df[\"sales\"].shift(4).values[0:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alphas = [0.95, 0.9, 0.8, 0.7, 0.5]\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = roll_mean_features(df, [128, 365, 546])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = ewm_features(df, alphas, lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.get_dummies(df, columns=[ 'day_of_week', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[ 'store_nbr', 'family', 'city', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train = df.loc[(df.date < \"2013-07-15\"), :]\n",
    "val = df.loc[(df.date >= \"2013-07-15\" ) & (df.date < \"2017-07-31\")]\n",
    "\n",
    "cols = [col for col in train.columns if col not in ['date', 'sales', 'transactions' ]]\n",
    "\n",
    "Y_train = train['sales']\n",
    "X_train = train[cols]\n",
    "\n",
    "Y_val = val['sales']\n",
    "X_val = val[cols]\n",
    "\n",
    "Y_train.shape, X_train.shape, Y_val.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rlsme(preds, target):\n",
    "    n = len(preds)\n",
    "    masked_arr = ~((preds == 0) & (target == 0))\n",
    "    preds, target = preds[masked_arr], target[masked_arr]\n",
    "    preds[np.where(preds < 0)] = 0\n",
    "    loss_val = np.sum(np.square((np.log(1+preds) - np.log(1 + target)))) / n\n",
    "    return np.sqrt(loss_val)\n",
    "\n",
    "\n",
    "def lgbm_rlsme(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    loss = rlsme(preds, labels)\n",
    "    return \"RMSLE\", loss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgb_params = {'num_leaves': 50,\n",
    "              'learning_rate': 0.03,\n",
    "              'feature_fraction': 0.8,\n",
    "              'max_depth': 30,\n",
    "              'verbose': 0,\n",
    "              'num_boost_round': 20000,\n",
    "              'early_stopping_rounds': 400,\n",
    "              'nthread': -1}\n",
    "\n",
    "trial_num = 'trial_11'\n",
    "os.makedirs(f'models/{trial_num}', exist_ok=True)\n",
    "pickle.dump(lgb_params, open(f\"models/{trial_num}/params.dat\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgbtrain_smape = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\n",
    "lgbval_smape = lgb.Dataset(data=X_val, label=Y_val, reference=lgbtrain_smape, feature_name=cols)\n",
    "\n",
    "lgbtrain_rlsme = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\n",
    "lgbval_rlsme = lgb.Dataset(data=X_val, label=Y_val, reference=lgbtrain_rlsme, feature_name=cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LightGBM -- Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_smape = lgb.train(lgb_params, lgbtrain_smape,\n",
    "                  valid_sets=[lgbtrain_smape, lgbval_smape],\n",
    "                  num_boost_round=lgb_params['num_boost_round'],\n",
    "                #   callbacks=[lgb.early_stopping(stopping_rounds=200)],\n",
    "                  feval=lgbm_smape,\n",
    "                  verbose_eval=100)\n",
    "\n",
    "pickle.dump(model_smape, open(f\"models/{trial_num}/lgbm_smape_1.dat\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_rlsme = lgb.train(lgb_params, lgbtrain_rlsme,\n",
    "                  valid_sets=[lgbtrain_rlsme, lgbval_rlsme],\n",
    "                  num_boost_round=lgb_params['num_boost_round'],\n",
    "                #   callbacks=[lgb.early_stopping(stopping_rounds=200)],\n",
    "                  feval=lgbm_rlsme,\n",
    "                  verbose_eval=100)\n",
    "\n",
    "pickle.dump(model_rlsme, open(f\"models/{trial_num}/lgbm_rlsme_1.dat\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_val_smape = model_smape.predict(X_val, num_iteration=model_smape.best_iteration)\n",
    "y_pred_val_rlsme = model_rlsme.predict(X_val, num_iteration=model_rlsme.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# smape(y_pred_val, Y_val)\n",
    "smape(y_pred_val_smape, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_lgb_importances(model_smape, num=30, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rlsme(y_pred_val_rlsme, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_lgb_importances(model_rlsme, num=30, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feat_imp_rmsle = plot_lgb_importances(model_rlsme, num=200)\n",
    "\n",
    "low_importance_rmsle = feat_imp_rmsle[feat_imp_rmsle[\"gain\"] <= 0.005][\"feature\"].values\n",
    "\n",
    "dff = df.drop(low_importance_rmsle, axis=1)\n",
    "\n",
    "cols_dff = [col for col in dff.columns if col not in ['date', \"sales\", \"year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = dff.loc[~df.sales.isna()]\n",
    "Y_train = train['sales']\n",
    "X_train = train[cols_dff]\n",
    "\n",
    "\n",
    "test = dff.loc[df.date >= \"2017-07-31\"]\n",
    "X_test = test[cols_dff]\n",
    "X_test.sales = np.nan\n",
    "\n",
    "Y_train.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# lgb_params = {'num_leaves': 10,\n",
    "#               'learning_rate': 0.02,\n",
    "#               'feature_fraction': 0.8,\n",
    "#               'max_depth': 5,\n",
    "#               'verbose': 0,\n",
    "#               'nthread': -1,\n",
    "#               \"num_boost_round\": model_rlsme.best_iteration}\n",
    "lgb_params[\"num_boost_round\"] = model_rlsme.best_iteration\n",
    "lgb_params[\"early_stopping_rounds\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgbtrain_all = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols_dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_model = lgb.train(lgb_params, lgbtrain_all, num_boost_round=model_rlsme.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_preds = final_model.predict(X_test, num_iteration=model_rlsme.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds[test_preds < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "df_sub = pd.read_csv(path + 'sample_submission.csv', index_col='id')\n",
    "df_sub.sales = test_preds\n",
    "df_sub.to_csv('submission.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs567",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c9a4f255cf9e2ad0bd567c9928466766a62645062bb2c38e3d7d5a79eff3a32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
